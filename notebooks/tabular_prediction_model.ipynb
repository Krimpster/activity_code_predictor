{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Imports and Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vicke\\Wizdo\\invoice_code_classifier\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "root_dir_path = os.getcwd()\n",
    "root_dir_path = os.path.abspath(os.path.split(root_dir_path)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_code</th>\n",
       "      <th>account_code</th>\n",
       "      <th>counterpart_code</th>\n",
       "      <th>business_code</th>\n",
       "      <th>activity_code</th>\n",
       "      <th>supplier</th>\n",
       "      <th>KPB AKTIVITETSKOD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29993</th>\n",
       "      <td>626604</td>\n",
       "      <td>50211</td>\n",
       "      <td>EP0000</td>\n",
       "      <td>5699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A_ADM_600_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16849</th>\n",
       "      <td>642700</td>\n",
       "      <td>60110</td>\n",
       "      <td>EÖ0000</td>\n",
       "      <td>5100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BREVENS BRUK AB</td>\n",
       "      <td>A_ORB_201_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30460</th>\n",
       "      <td>645002</td>\n",
       "      <td>60129</td>\n",
       "      <td>EP0000</td>\n",
       "      <td>5110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DBO JÖNSSON;BIRGIT</td>\n",
       "      <td>A_SÄB_305_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45612</th>\n",
       "      <td>666500</td>\n",
       "      <td>64503</td>\n",
       "      <td>EP0000</td>\n",
       "      <td>5110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KIHLSTRÖM;MYLÉNE</td>\n",
       "      <td>A_SÄB_305_228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17190</th>\n",
       "      <td>642802</td>\n",
       "      <td>54802</td>\n",
       "      <td>EP0000</td>\n",
       "      <td>5100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A_ORB_201_19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       clean_code  account_code counterpart_code  business_code  \\\n",
       "29993      626604         50211           EP0000           5699   \n",
       "16849      642700         60110           EÖ0000           5100   \n",
       "30460      645002         60129           EP0000           5110   \n",
       "45612      666500         64503           EP0000           5110   \n",
       "17190      642802         54802           EP0000           5100   \n",
       "\n",
       "       activity_code            supplier KPB AKTIVITETSKOD  \n",
       "29993            NaN                 NaN      A_ADM_600_10  \n",
       "16849            NaN     BREVENS BRUK AB      A_ORB_201_10  \n",
       "30460            NaN  DBO JÖNSSON;BIRGIT       A_SÄB_305_0  \n",
       "45612            NaN    KIHLSTRÖM;MYLÉNE     A_SÄB_305_228  \n",
       "17190            NaN                 NaN      A_ORB_201_19  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_save_path = rf'{root_dir_path}/models/'\n",
    "\n",
    "train_df = pd.read_csv(rf'{root_dir_path}/data/train_val_csv.csv', delimiter= '|', encoding='utf-8', index_col=0)\n",
    "\n",
    "train_data = TabularDataset(train_df)\n",
    "label = \"KPB AKTIVITETSKOD\"\n",
    "\n",
    "train_data = train_data.sample(n=15000, random_state = 42)\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"C:/Users/vicke/Wizdo/invoice_code_classifier/models/\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.9.20\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "CPU Count:          4\n",
      "Memory Avail:       5.13 GB / 15.88 GB (32.3%)\n",
      "Disk Space Avail:   64.52 GB / 236.39 GB (27.3%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality']\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"C:/Users/vicke/Wizdo/invoice_code_classifier/models/\"\n",
      "Train Data Rows:    15000\n",
      "Train Data Columns: 6\n",
      "Label Column:       KPB AKTIVITETSKOD\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 344) unique label values:  ['A_ADM_600_10', 'A_ORB_201_10', 'A_SÄB_305_0', 'A_SÄB_305_228', 'A_ORB_201_19', 'A_VUX_451_3', 'A_SÄB_305_203', 'A_LSS_106_38', 'A_SÄB_305_211', 'A_SÄB_305_222']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 289 out of 344 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9824\n",
      "Train Data Class Count: 289\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5248.31 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.28 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 1 | ['activity_code']\n",
      "\t\t('int', [])    : 3 | ['clean_code', 'account_code', 'business_code']\n",
      "\t\t('object', []) : 2 | ['counterpart_code', 'supplier']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 2 | ['counterpart_code', 'supplier']\n",
      "\t\t('float', [])    : 1 | ['activity_code']\n",
      "\t\t('int', [])      : 3 | ['clean_code', 'account_code', 'business_code']\n",
      "\t0.3s = Fit runtime\n",
      "\t6 features in original data used to generate 6 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.49 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.43s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 13262, Val Rows: 1474\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.5522\t = Validation score   (accuracy)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.6886\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.2592\t = Validation score   (accuracy)\n",
      "\t90.83s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's multi_error: 0.438942\n",
      "[2000]\tvalid_set's multi_error: 0.407734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Large GBM model size may cause OOM error if training continues\n",
      "Available Memory: 2756 MB\n",
      "Estimated GBM model size: 2760 MB\n",
      "Warning: Early stopped GBM model prior to optimal result to avoid OOM error. Please increase available memory to avoid subpar model quality.\n",
      "\t0.6194\t = Validation score   (accuracy)\n",
      "\t1140.46s\t = Training   runtime\n",
      "\t183.95s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.7341\t = Validation score   (accuracy)\n",
      "\t95.36s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 53 due to low memory. Expected memory usage reduced from 83.67% -> 15.0% of available memory...\n",
      "\t0.7917\t = Validation score   (accuracy)\n",
      "\t2.66s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\tWarning: Potentially not enough memory to safely train model. Estimated to require 2.555 GB out of 6.029 GB available memory (42.383%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo avoid this warning, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.11 to avoid the warning)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 46 due to low memory. Expected memory usage reduced from 97.38% -> 15.0% of available memory...\n",
      "\t0.8229\t = Validation score   (accuracy)\n",
      "\t3.37s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n"
     ]
    }
   ],
   "source": [
    "column_predictor = TabularPredictor(label=label, path=model_save_path).fit(train_data, presets='medium_quality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = TabularDataset(train_df)\n",
    "val_data = val_data.sample(n=30000, random_state = 42)\n",
    "val_data.drop(columns=['KPB AKTIVITETSKOD'])\n",
    "\n",
    "val_predictor = TabularPredictor.load(model_save_path)\n",
    "\n",
    "y_pred = val_predictor.predict(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictor.leaderboard(val_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Wizdo_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
